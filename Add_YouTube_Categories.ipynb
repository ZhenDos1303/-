{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:05.963023Z",
     "start_time": "2025-11-12T00:42:05.659277Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:07.185298Z",
     "start_time": "2025-11-12T00:42:05.979489Z"
    }
   },
   "source": [
    "df = pd.read_csv('merged_vk_youtube_dataset.csv', encoding='utf-8-sig')\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:07.216282Z",
     "start_time": "2025-11-12T00:42:07.198377Z"
    }
   },
   "source": [
    "possible_fields = ['video_id_youtube', 'videoId', 'youtube_video_id', 'youtube_id', 'id', 'youtubeId']\n",
    "found_field = None\n",
    "for field in possible_fields:\n",
    "    if field in df.columns:\n",
    "        found_field = field\n",
    "        break\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:07.250464Z",
     "start_time": "2025-11-12T00:42:07.241325Z"
    }
   },
   "source": [
    "YOUTUBE_API_KEY = \"AIzaSyCPF8G9khU4YQUyq5AENuHSwhgOIqGs-sg\"\n",
    "YOUTUBE_VIDEO_ID_FIELD = found_field if found_field else \"videoId\"\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:07.289441Z",
     "start_time": "2025-11-12T00:42:07.276517Z"
    }
   },
   "source": [
    "YOUTUBE_CATEGORIES = {\n",
    "    '1': 'Film & Animation',\n",
    "    '2': 'Autos & Vehicles',\n",
    "    '10': 'Music',\n",
    "    '15': 'Pets & Animals',\n",
    "    '17': 'Sports',\n",
    "    '19': 'Travel & Events',\n",
    "    '20': 'Gaming',\n",
    "    '22': 'People & Blogs',\n",
    "    '23': 'Comedy',\n",
    "    '24': 'Entertainment',\n",
    "    '25': 'News & Politics',\n",
    "    '26': 'Howto & Style',\n",
    "    '27': 'Education',\n",
    "    '28': 'Science & Technology',\n",
    "    '29': 'Nonprofits & Activism'\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:07.339852Z",
     "start_time": "2025-11-12T00:42:07.323572Z"
    }
   },
   "source": [
    "def get_youtube_categories_batch(video_ids, api_key):\n",
    "    if not video_ids:\n",
    "        return {}\n",
    "    video_ids_str = ','.join(str(vid) for vid in video_ids[:50])\n",
    "    url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "    params = {\n",
    "        'id': video_ids_str,\n",
    "        'part': 'snippet',\n",
    "        'key': api_key\n",
    "    }\n",
    "    result = {}\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if 'items' in data:\n",
    "            for item in data['items']:\n",
    "                video_id = str(item['id'])\n",
    "                category_id = item['snippet'].get('categoryId')\n",
    "                category_name = YOUTUBE_CATEGORIES.get(str(category_id), f'Unknown ({category_id})')\n",
    "                result[video_id] = (str(category_id), category_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return result\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:07.460472Z",
     "start_time": "2025-11-12T00:42:07.358052Z"
    }
   },
   "source": [
    "youtube_rows = df[df[YOUTUBE_VIDEO_ID_FIELD].notna()].copy()\n",
    "unique_video_ids = youtube_rows[YOUTUBE_VIDEO_ID_FIELD].unique()\n",
    "progress_file = 'youtube_categories_cache.json'\n",
    "category_cache = {}\n",
    "if os.path.exists(progress_file):\n",
    "    try:\n",
    "        with open(progress_file, 'r', encoding='utf-8') as f:\n",
    "            saved_cache = json.load(f)\n",
    "            for k, v in saved_cache.items():\n",
    "                category_cache[str(k)] = tuple(v) if isinstance(v, list) else v\n",
    "    except Exception:\n",
    "        pass\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:12.008226Z",
     "start_time": "2025-11-12T00:42:07.473071Z"
    }
   },
   "source": [
    "BATCH_SIZE = 50\n",
    "TOTAL_VIDEOS = len(unique_video_ids)\n",
    "BATCHES_NEEDED = (TOTAL_VIDEOS + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "for i in tqdm(range(0, TOTAL_VIDEOS, BATCH_SIZE), desc=\"Обработка батчей\", total=BATCHES_NEEDED):\n",
    "    batch = unique_video_ids[i:i+BATCH_SIZE]\n",
    "    batch_to_fetch = [str(vid) for vid in batch if str(vid) not in category_cache]\n",
    "    if batch_to_fetch:\n",
    "        batch_results = get_youtube_categories_batch(batch_to_fetch, YOUTUBE_API_KEY)\n",
    "        category_cache.update(batch_results)\n",
    "        time.sleep(1.0)\n",
    "    if (i // BATCH_SIZE) % 5 == 0 and i > 0:\n",
    "        try:\n",
    "            with open(progress_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(category_cache, f, ensure_ascii=False, indent=2)\n",
    "        except Exception:\n",
    "            pass\n",
    "try:\n",
    "    with open(progress_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(category_cache, f, ensure_ascii=False, indent=2)\n",
    "except Exception:\n",
    "    pass\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка батчей: 100%|██████████| 177/177 [00:04<00:00, 40.16it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:12.132256Z",
     "start_time": "2025-11-12T00:42:12.099437Z"
    }
   },
   "source": [
    "def get_category_id(video_id):\n",
    "    if pd.isna(video_id):\n",
    "        return None\n",
    "    video_id_str = str(video_id)\n",
    "    if video_id_str in category_cache:\n",
    "        return category_cache[video_id_str][0]\n",
    "    return None\n",
    "\n",
    "def get_category_name(video_id):\n",
    "    if pd.isna(video_id):\n",
    "        return None\n",
    "    video_id_str = str(video_id)\n",
    "    if video_id_str in category_cache:\n",
    "        return category_cache[video_id_str][1]\n",
    "    return None\n",
    "\n",
    "df['youtube_category_id'] = df[YOUTUBE_VIDEO_ID_FIELD].apply(get_category_id)\n",
    "df['youtube_category_name'] = df[YOUTUBE_VIDEO_ID_FIELD].apply(get_category_name)\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T00:42:41.939676Z",
     "start_time": "2025-11-12T00:42:12.151803Z"
    }
   },
   "source": [
    "df.to_csv('merged_vk_youtube_dataset_with_categories.csv', index=False, encoding='utf-8-sig')\n",
    "try:\n",
    "    df.to_excel('merged_vk_youtube_dataset_with_categories.xlsx', index=False, engine='openpyxl')\n",
    "except Exception:\n",
    "    pass\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
